{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Prepare)\n",
    "\n",
    "Today's guided module project will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills. The competition will begin\n",
    "\n",
    "## Learning Objectives\n",
    "* <a href=\"#p0\">Part 0</a>: Kaggle Competition\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Sklearn pipelines allow you to stitch together multiple components of a machine learning process. The idea is that you can pass you raw data and get predictions out of the pipeline. This ability to pass raw input and receive a prediction from a singular class makes pipelines well suited for production, because you can pickle a a pipeline without worry about other data preprocessing steps. \n",
    "\n",
    "*Note:* Each time we call the pipeline during grid search, each component is fit again. The vectorizer (tf-idf) is transforming our entire vocabulary during each cross-validation fold. That transformation adds significant run time to our grid search. There *might* be interactions between the vectorizer and our classifier, so we estimate their performance together in the code below. However, if your goal is to reduce run time. Train your vectorizer separately (ie out of the grid-searched pipeline). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism',\n",
    "              'talk.religion.misc']\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "head",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4NLP\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'head'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-304fa4ce4ebd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\U4NLP\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: head"
     ]
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline Components\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect),\n",
    "                 # Classifier\n",
    "                 ('clf', rfc)\n",
    "                ])\n",
    "\n",
    "# The pipeline puts together a bunch fit then transform,fit then predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   53.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.75, 1.0), 'vect__min_df': (0.02, 0.05), 'vect__max_features': (500, 1000), 'clf__n_estimators': (5, 10), 'clf__max_depth': (15, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': ( 0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8891481913652275"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(['Send me lots of money now', 'you won the lottery in Nigeria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('./kaggledata/train.csv')\n",
    "test = pd.read_csv('./kaggledata/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  50 | elapsed:   35.9s remaining:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  50 | elapsed:   37.0s remaining:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:   38.2s remaining:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  50 | elapsed:   38.4s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  50 | elapsed:   40.6s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:   41.2s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   41.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...    subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False))]),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'vect__max_df': (0.75, 1.0), 'vect__min_df': (0.02, 0.05), 'vect__max_features': (500, 1000), 'clf__n_estimators': (5, 10), 'clf__max_depth': (5, 10, 15, 20), 'clf__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002850B1DFA58>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=50)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': ( 0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10),\n",
    "    'clf__max_depth':(5,10,15,20),\n",
    "    'clf__min_samples_leaf': randint(2,15)\n",
    "}\n",
    "\n",
    "rando_search = RandomizedSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=50)\n",
    "rando_search.fit(train.description, train.ratingCategory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this compeition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = rando_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "submission.to_csv('./kaggledata/submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve 90% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, # Just here for demo. \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df':[.9, .95, 1.0],\n",
    "    'clf__n_estimators':[5,10,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "\n",
    "# Pipe\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('lsi', Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm=...obs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 49.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('lsi', Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm=...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'lsi__svd__n_components': [10, 100, 250], 'lsi__vect__max_df': [0.9, 0.95, 1.0], 'clf__n_estimators': (5, 10), 'clf__max_depth': (5, 10, 15, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df':[.9, .95, 1.0],\n",
    "    'clf__n_estimators':(5, 10),\n",
    "    'clf__max_depth':(5,10,15,20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=25)\n",
    "grid_search.fit(train.description, train.ratingCategory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* You are only allowed two submissions a day. Only submit if you feel you cannot achieve higher test accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./kaggledata/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Two bananas in pyjamas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "bananas_vector = doc.vector\n",
    "print(len(bananas_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = get_word_vectors(train['description'])\n",
    "\n",
    "len(X) == len(train.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\Anaconda3\\envs\\U4NLP\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9918319719953326"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X, data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    \n",
    "    'max_depth' : randint(3,10),\n",
    "    #'max_features': 'log2',\n",
    "    'min_samples_leaf': randint(2,15)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed: 22.1min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed: 23.9min\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed: 27.7min\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed: 27.7min\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed: 30.1min\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed: 31.3min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed: 31.3min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 31.6min\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed: 33.1min\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed: 33.1min\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 33.4min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed: 33.8min\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed: 34.2min\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed: 34.2min\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=-1)]: Done 127 tasks      | elapsed: 37.9min\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed: 38.0min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed: 38.8min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed: 38.8min\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed: 40.5min\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed: 41.4min\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed: 41.6min\n",
      "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed: 41.8min\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed: 41.8min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 42.6min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 42.6min\n",
      "[Parallel(n_jobs=-1)]: Done 139 tasks      | elapsed: 44.0min\n",
      "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed: 44.1min\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed: 45.2min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 45.2min\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed: 46.4min\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed: 46.4min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed: 46.6min\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed: 46.7min\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed: 46.9min\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed: 46.9min\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed: 47.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed: 48.5min\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed: 48.5min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed: 48.7min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 48.8min\n",
      "[Parallel(n_jobs=-1)]: Done 159 tasks      | elapsed: 48.9min\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed: 49.0min\n",
      "[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done 163 tasks      | elapsed: 52.1min\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed: 52.2min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 52.3min\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed: 52.4min\n",
      "[Parallel(n_jobs=-1)]: Done 167 tasks      | elapsed: 52.5min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 52.6min\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed: 54.5min\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed: 54.5min\n",
      "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed: 55.3min\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed: 55.4min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 55.5min\n",
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed: 55.6min\n",
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed: 55.7min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 55.8min\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed: 57.7min\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed: 57.7min\n",
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed: 58.4min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed: 58.5min\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed: 59.9min\n",
      "[Parallel(n_jobs=-1)]: Done 182 tasks      | elapsed: 60.0min\n",
      "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed: 60.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 60.2min\n",
      "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed: 61.8min\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed: 61.8min\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed: 62.1min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed: 62.1min\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed: 62.8min\n",
      "[Parallel(n_jobs=-1)]: Done 190 tasks      | elapsed: 63.0min\n",
      "[Parallel(n_jobs=-1)]: Done 191 tasks      | elapsed: 63.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 63.4min\n",
      "[Parallel(n_jobs=-1)]: Done 193 tasks      | elapsed: 63.7min\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed: 63.7min\n",
      "[Parallel(n_jobs=-1)]: Done 195 tasks      | elapsed: 64.4min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 64.4min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed: 64.4min\n",
      "[Parallel(n_jobs=-1)]: Done 198 tasks      | elapsed: 64.6min\n",
      "[Parallel(n_jobs=-1)]: Done 199 tasks      | elapsed: 64.9min\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed: 64.9min\n",
      "[Parallel(n_jobs=-1)]: Done 201 tasks      | elapsed: 65.0min\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed: 65.0min\n",
      "[Parallel(n_jobs=-1)]: Done 203 tasks      | elapsed: 65.5min\n",
      "[Parallel(n_jobs=-1)]: Done 204 tasks      | elapsed: 65.6min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 65.6min\n",
      "[Parallel(n_jobs=-1)]: Done 206 tasks      | elapsed: 65.7min\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed: 66.0min\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed: 66.0min\n",
      "[Parallel(n_jobs=-1)]: Done 209 tasks      | elapsed: 66.1min\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed: 66.2min\n",
      "[Parallel(n_jobs=-1)]: Done 211 tasks      | elapsed: 68.2min\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed: 68.2min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 68.3min\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed: 68.4min\n",
      "[Parallel(n_jobs=-1)]: Done 215 tasks      | elapsed: 68.7min\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed: 68.7min\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed: 68.8min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed: 68.9min\n",
      "[Parallel(n_jobs=-1)]: Done 219 tasks      | elapsed: 70.9min\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed: 70.9min\n",
      "[Parallel(n_jobs=-1)]: Done 221 tasks      | elapsed: 72.0min\n",
      "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed: 72.1min\n",
      "[Parallel(n_jobs=-1)]: Done 223 tasks      | elapsed: 72.4min\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed: 72.4min\n",
      "[Parallel(n_jobs=-1)]: Done 225 tasks      | elapsed: 72.5min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 72.6min\n",
      "[Parallel(n_jobs=-1)]: Done 227 tasks      | elapsed: 74.5min\n",
      "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed: 74.6min\n",
      "[Parallel(n_jobs=-1)]: Done 229 tasks      | elapsed: 75.7min\n",
      "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed: 75.7min\n",
      "[Parallel(n_jobs=-1)]: Done 231 tasks      | elapsed: 76.6min\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed: 76.6min\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed: 76.7min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 76.8min\n",
      "[Parallel(n_jobs=-1)]: Done 235 tasks      | elapsed: 78.8min\n",
      "[Parallel(n_jobs=-1)]: Done 241 out of 250 | elapsed: 81.1min remaining:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 247 out of 250 | elapsed: 84.5min remaining:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 84.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=25, n_jobs=-1,\n",
       "          param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D1222FAC50>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D143192470>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "search = RandomizedSearchCV(clf, param_dist, cv=10, n_iter=25, n_jobs=-1, verbose=50)\n",
    "search.fit(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vec = get_word_vectors(test['description'])\n",
    "\n",
    "len(test_vec) == len(test.description)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = search.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred2})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "\n",
    "submission.to_csv(f'./kaggledata/submission4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "To review this module: \n",
    "* Continue working on the Kaggle comeptition\n",
    "* Find another text classification task to work on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
